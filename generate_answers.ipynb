{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eU-tsiNvES9a"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UycsqSk-DnAs"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gMS65QN3WDXO"
   },
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pa\n",
    "import pandas as pd\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kt_nOsDDt0-"
   },
   "source": [
    "## Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qx8U_GaXWE_N"
   },
   "outputs": [],
   "source": [
    "table = pa.read_table('test-00000-of-00001.parquet')  # We dind't donwload the dataset using datasets library because it caused an exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "0pQR4qXmWQbA",
    "outputId": "ec256425-1092-44d4-b24d-fd71e4745b19"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_index</th>\n",
       "      <th>cot_content</th>\n",
       "      <th>category</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Typical advertising regulatory bodies suggest,...</td>\n",
       "      <td>[Safe practices, Fear, Jealousy, Trivial, Unsa...</td>\n",
       "      <td>I</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>business</td>\n",
       "      <td>ori_mmlu-business_ethics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Managers are entrusted to run the company in t...</td>\n",
       "      <td>[Shareholders, Diligence, Self-interest, Share...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>business</td>\n",
       "      <td>ori_mmlu-business_ethics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>There are two main issues associated with ____...</td>\n",
       "      <td>[Down, Autonomy, Remuneration, Benefit, Down, ...</td>\n",
       "      <td>J</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>business</td>\n",
       "      <td>ori_mmlu-business_ethics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>_______ locate morality beyond the sphere of r...</td>\n",
       "      <td>[Ethical egoism, Ethics of duty, Postmodern et...</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>business</td>\n",
       "      <td>ori_mmlu-business_ethics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Some of key differences between Islamic finan...</td>\n",
       "      <td>[Interest, Certain, Assured, Both tangible and...</td>\n",
       "      <td>G</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>business</td>\n",
       "      <td>ori_mmlu-business_ethics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      question  \\\n",
       "question_id                                                      \n",
       "70           Typical advertising regulatory bodies suggest,...   \n",
       "71           Managers are entrusted to run the company in t...   \n",
       "72           There are two main issues associated with ____...   \n",
       "73           _______ locate morality beyond the sphere of r...   \n",
       "74            Some of key differences between Islamic finan...   \n",
       "\n",
       "                                                       options answer  \\\n",
       "question_id                                                             \n",
       "70           [Safe practices, Fear, Jealousy, Trivial, Unsa...      I   \n",
       "71           [Shareholders, Diligence, Self-interest, Share...      F   \n",
       "72           [Down, Autonomy, Remuneration, Benefit, Down, ...      J   \n",
       "73           [Ethical egoism, Ethics of duty, Postmodern et...      C   \n",
       "74           [Interest, Certain, Assured, Both tangible and...      G   \n",
       "\n",
       "             answer_index cot_content  category                       src  \n",
       "question_id                                                                \n",
       "70                      8              business  ori_mmlu-business_ethics  \n",
       "71                      5              business  ori_mmlu-business_ethics  \n",
       "72                      9              business  ori_mmlu-business_ethics  \n",
       "73                      2              business  ori_mmlu-business_ethics  \n",
       "74                      6              business  ori_mmlu-business_ethics  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = table.to_pandas()\n",
    "df = df.set_index('question_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 600\n",
    "\n",
    "# Ensure reproducibility setting the seed \n",
    "df = df.sample(NUM_SAMPLES, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_index</th>\n",
       "      <th>cot_content</th>\n",
       "      <th>category</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8603</th>\n",
       "      <td>Compute the area of the triangle whose altitud...</td>\n",
       "      <td>[56\\sqrt{15}, 60\\sqrt{7}, 240\\sqrt{7}/7, 48\\sq...</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>math</td>\n",
       "      <td>ori_mmlu-high_school_mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>What is the relationship between the formal so...</td>\n",
       "      <td>[Treaties supersede custom, Treaties and Gener...</td>\n",
       "      <td>J</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>law</td>\n",
       "      <td>ori_mmlu-international_law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>The elasticity of supply is typically greater ...</td>\n",
       "      <td>[producers have less capital to invest., produ...</td>\n",
       "      <td>G</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>economics</td>\n",
       "      <td>ori_mmlu-high_school_microeconomics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>Which of the following conditions is a peroxis...</td>\n",
       "      <td>[Zellweger syndrome, Maple syrup urine disease...</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>health</td>\n",
       "      <td>ori_mmlu-medical_genetics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10472</th>\n",
       "      <td>Define the following terms, making clear the d...</td>\n",
       "      <td>[Byte is a collection of 4 bits, Bit is the sm...</td>\n",
       "      <td>J</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>computer science</td>\n",
       "      <td>stemez-ComputerScience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>Piaget’s theory describes stages of cognitive ...</td>\n",
       "      <td>[During adolescence only, From birth to late c...</td>\n",
       "      <td>J</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>psychology</td>\n",
       "      <td>ori_mmlu-professional_psychology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>Assume a population of garden peas in genetic ...</td>\n",
       "      <td>[0.54FF + 0.12Ff + 0.34ff, 0.42FF + 0.36Ff + 0...</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>biology</td>\n",
       "      <td>stemez-Genetics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>Which culture, previously-known as the temple-...</td>\n",
       "      <td>[Hohokam, Folsom, Adena, Ancestral Puebloan, M...</td>\n",
       "      <td>E</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>history</td>\n",
       "      <td>ori_mmlu-prehistory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10380</th>\n",
       "      <td>Which of the following is NOT a reasonable jus...</td>\n",
       "      <td>[There is no other work for the processor to d...</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>computer science</td>\n",
       "      <td>ori_mmlu-college_computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11268</th>\n",
       "      <td>The goal of cognitive-behavioral therapy is to</td>\n",
       "      <td>[enhance physical strength., reward good behav...</td>\n",
       "      <td>I</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>philosophy</td>\n",
       "      <td>ori_mmlu-moral_disputes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      question  \\\n",
       "question_id                                                      \n",
       "8603         Compute the area of the triangle whose altitud...   \n",
       "1663         What is the relationship between the formal so...   \n",
       "7113         The elasticity of supply is typically greater ...   \n",
       "6220         Which of the following conditions is a peroxis...   \n",
       "10472        Define the following terms, making clear the d...   \n",
       "...                                                        ...   \n",
       "2635         Piaget’s theory describes stages of cognitive ...   \n",
       "3404         Assume a population of garden peas in genetic ...   \n",
       "5034         Which culture, previously-known as the temple-...   \n",
       "10380        Which of the following is NOT a reasonable jus...   \n",
       "11268           The goal of cognitive-behavioral therapy is to   \n",
       "\n",
       "                                                       options answer  \\\n",
       "question_id                                                             \n",
       "8603         [56\\sqrt{15}, 60\\sqrt{7}, 240\\sqrt{7}/7, 48\\sq...      C   \n",
       "1663         [Treaties supersede custom, Treaties and Gener...      J   \n",
       "7113         [producers have less capital to invest., produ...      G   \n",
       "6220         [Zellweger syndrome, Maple syrup urine disease...      A   \n",
       "10472        [Byte is a collection of 4 bits, Bit is the sm...      J   \n",
       "...                                                        ...    ...   \n",
       "2635         [During adolescence only, From birth to late c...      J   \n",
       "3404         [0.54FF + 0.12Ff + 0.34ff, 0.42FF + 0.36Ff + 0...      F   \n",
       "5034         [Hohokam, Folsom, Adena, Ancestral Puebloan, M...      E   \n",
       "10380        [There is no other work for the processor to d...      C   \n",
       "11268        [enhance physical strength., reward good behav...      I   \n",
       "\n",
       "             answer_index cot_content          category  \\\n",
       "question_id                                               \n",
       "8603                    2                          math   \n",
       "1663                    9                           law   \n",
       "7113                    6                     economics   \n",
       "6220                    0                        health   \n",
       "10472                   9              computer science   \n",
       "...                   ...         ...               ...   \n",
       "2635                    9                    psychology   \n",
       "3404                    5                       biology   \n",
       "5034                    4                       history   \n",
       "10380                   2              computer science   \n",
       "11268                   8                    philosophy   \n",
       "\n",
       "                                             src  \n",
       "question_id                                       \n",
       "8603            ori_mmlu-high_school_mathematics  \n",
       "1663                  ori_mmlu-international_law  \n",
       "7113         ori_mmlu-high_school_microeconomics  \n",
       "6220                   ori_mmlu-medical_genetics  \n",
       "10472                     stemez-ComputerScience  \n",
       "...                                          ...  \n",
       "2635            ori_mmlu-professional_psychology  \n",
       "3404                             stemez-Genetics  \n",
       "5034                         ori_mmlu-prehistory  \n",
       "10380          ori_mmlu-college_computer_science  \n",
       "11268                    ori_mmlu-moral_disputes  \n",
       "\n",
       "[600 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRIX58ibEpyr"
   },
   "source": [
    "## Prompts & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARTIAN_API_KEY = \"YOUR_API_KEY_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kMPolcMiSqBU"
   },
   "outputs": [],
   "source": [
    "answers_selected = \"two\" # Number of options the model must choose in its first respose\n",
    "\n",
    "\n",
    "SELECT_ANSWERS_PROMPT = \"\"\"\n",
    "You will be given a multiple-choice question. Your task is to select the {answers_selected} most likely correct answers from the list of options, based on reasoning and evidence.\n",
    "\n",
    "For each selected option:\n",
    "- Provide the number of the answer.\n",
    "- Write a concise justification explaining why it is a strong candidate.\n",
    "\n",
    "⚠️ IMPORTANT:\n",
    "- Do NOT select more than {answers_selected} options.\n",
    "- Do NOT include any information or analysis about options you do NOT select.\n",
    "- Do NOT include extra commentary or headers.\n",
    "- Follow the format *exactly* as shown below.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "OPTIONS:\n",
    "{options_formatted}\n",
    "\n",
    "====================\n",
    "✅ EXPECTED ANSWER FORMAT:\n",
    "Option: 0\n",
    "Justification: This option directly addresses the main point of the question and aligns with known facts or logical reasoning.\n",
    "\n",
    "Option: 3\n",
    "Justification: This option is also supported by relevant evidence and complements the reasoning in Option 1.\n",
    "====================\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "SELECT_BEST_OPTION_PROMPT = f\"\"\"\n",
    "Now, based on your justifications and the {answers_selected} best options previously selected, choose the SINGLE most likely correct answer.\n",
    "\n",
    "Provide:\n",
    "- The number of the best option\n",
    "- A short reason why this option is stronger than the other(s)\n",
    "- An estimated probability (between 0 and 1) that this answer is correct\n",
    "\n",
    "⚠️ IMPORTANT:\n",
    "- Do NOT include general reflections or unrelated commentary.\n",
    "- Do NOT reference options that were not selected in the prior step.\n",
    "- Use only the format below—no extra content or markdown.\n",
    "\n",
    "====================\n",
    "✅ EXPECTED ANSWER FORMAT:\n",
    "Final Answer: 2\n",
    "Reason: Option 2 covers the key concepts more completely and directly than Option 1.\n",
    "Confidence: 0.85\n",
    "====================\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "JUDGE_COMPARISON_PROMPT = \"\"\"\n",
    "You are an expert evaluator reviewing responses from multiple AI models that have answered the same multiple-choice question.\n",
    "\n",
    "Each model provided:\n",
    "1. {answers_selected} top candidate answers with justifications.\n",
    "2. A final selected answer and a confidence score.\n",
    "3. Supporting reasoning for that final answer.\n",
    "\n",
    "Your tasks:\n",
    "- Evaluate the correctness and depth of each model's justifications.\n",
    "- Assess the logic behind the final answer and the confidence score.\n",
    "- Review all model responses to determine the correct answer to the question.\n",
    "- Identify the correct answer to the question and provide a justification.\n",
    "- Estimate the probability that your selected answer is correct.\n",
    "\n",
    "CRITICAL INSTRUCTIONS:\n",
    "⚠️ STRICTLY follow the format below.\n",
    "⚠️ Do NOT add extra commentary, explanations, introductions, or conclusions.\n",
    "⚠️ Do NOT summarize the question or repeat content from the prompt.\n",
    "⚠️ Only write what is required under each section.\n",
    "\n",
    "Criteria to consider:\n",
    "- Accuracy of the final answer\n",
    "- Quality and depth of justifications\n",
    "- Logical coherence of reasoning\n",
    "- Clarity and precision\n",
    "- Appropriateness of the confidence estimate\n",
    "Please review the question and responses below:\n",
    "============================\n",
    "QUESTION:\n",
    "{question}\n",
    "OPTIONS:\n",
    "{options_formatted}\n",
    "\n",
    "============================\n",
    "MODEL RESPONSES:\n",
    "{model_responses}\n",
    "\n",
    "====================\n",
    "✅ EXPECTED ANSWER FORMAT:\n",
    "Evaluation Summary:\n",
    "Model 0: Strong justifications and coherent logic, though the confidence score was slightly too low given the quality of reasoning.\n",
    "Model 1: Final answer was incorrect due to errors in the reasoning.\n",
    "\n",
    "Correct Answer: 1\n",
    "Justification: Option 1 aligns most closely with the core reasoning required by the question, and is well supported by evidence in the selected justifications.\n",
    "Judge Confidence: 0.88\n",
    "====================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "91ak75U9JPi3"
   },
   "outputs": [],
   "source": [
    "# Parse the responses to the prompts\n",
    "def parse_select_best_option(response):\n",
    "    pattern = (\n",
    "        r\"Final Answer:\\s*(\\d+)\\s*\"\n",
    "        r\"Reason:\\s*(.*?)\\s*\"\n",
    "        r\"Confidence:\\s*(0(?:\\.\\d+)?|1(?:\\.0+)?)\"\n",
    "    )\n",
    "    match = re.search(pattern, response, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"Response does not match the expected format.\")\n",
    "\n",
    "    option, reason, confidence = match.groups()\n",
    "    return option, reason, confidence\n",
    "\n",
    "\n",
    "def parse_judge_evaluation(response):\n",
    "    pattern = (\n",
    "        r\"Evaluation Summary:\\s*(.*?)\"\n",
    "        r\"Correct Answer:\\s*(\\d+)\\s*\"\n",
    "        r\"Justification:\\s*(.*?)\"\n",
    "        r\"Judge Confidence:\\s*(0(?:\\.\\d+)?|1(?:\\.0+)?)\"\n",
    "    )\n",
    "    match = re.search(pattern, response, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"Response does not match the expected judge format.\")\n",
    "\n",
    "    summary, correct_answer, justification, confidence = match.groups()\n",
    "    return summary, correct_answer, justification, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_qrTSRcynqll"
   },
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=MARTIAN_API_KEY,\n",
    "    base_url=\"https://withmartian.com/api/openai/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lokcOlgHuev"
   },
   "source": [
    "# Monolithic baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "R1O3auDJRSpD"
   },
   "outputs": [],
   "source": [
    "MODEL_LIST = [\"openai/openai/gpt-4.1-nano\", \"anthropic/anthropic/claude-3-5-haiku-latest\", \"gemini/gemini/gemini-2.0-flash\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "s3Zry3huoV2o"
   },
   "outputs": [],
   "source": [
    "def get_response(model, prompt, message_history):\n",
    "    message_history=message_history + [\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": prompt,\n",
    "          }\n",
    "      ]\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = message_history\n",
    "    )\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "\n",
    "    message_history = message_history + [        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": response,\n",
    "        }]\n",
    "\n",
    "    return message_history, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZYWm4iNTkNx2",
    "outputId": "053b1e77-4ac4-451b-80b3-c862300afa60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'openai/openai/gpt-4.1-nano': {'question_id': [],\n",
       "  'question': [],\n",
       "  'options': [],\n",
       "  'category': [],\n",
       "  'correct_answer': [],\n",
       "  'first_prompt': [],\n",
       "  'first_response': [],\n",
       "  'second_response': [],\n",
       "  'selected_option': [],\n",
       "  'reason': [],\n",
       "  'confidence': []},\n",
       " 'anthropic/anthropic/claude-3-5-haiku-latest': {'question_id': [],\n",
       "  'question': [],\n",
       "  'options': [],\n",
       "  'category': [],\n",
       "  'correct_answer': [],\n",
       "  'first_prompt': [],\n",
       "  'first_response': [],\n",
       "  'second_response': [],\n",
       "  'selected_option': [],\n",
       "  'reason': [],\n",
       "  'confidence': []},\n",
       " 'gemini/gemini/gemini-2.0-flash': {'question_id': [],\n",
       "  'question': [],\n",
       "  'options': [],\n",
       "  'category': [],\n",
       "  'correct_answer': [],\n",
       "  'first_prompt': [],\n",
       "  'first_response': [],\n",
       "  'second_response': [],\n",
       "  'selected_option': [],\n",
       "  'reason': [],\n",
       "  'confidence': []}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionaries that are going to be used to created the DataFrames storing each model's responses\n",
    "dicts = {model_name: {'question_id': [], 'question': [], 'options': [], 'category': [], 'correct_answer': [], 'first_prompt':[], 'first_response': [], 'second_response': [],\n",
    "                     'selected_option': [], 'reason': [], 'confidence': []} for model_name in MODEL_LIST}\n",
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4TMJ_WmDS1l0"
   },
   "outputs": [],
   "source": [
    "def format_options(options):\n",
    "  return \"\\n\".join(f\"{i}. {option}\" for i, option in enumerate(options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVopAUtCOEw9",
    "outputId": "691519a3-7536-4c80-c983-f5b69e3e1f52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████████████████████████████████████████                    | 447/600 [1:24:42<28:16, 11.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 600/600 [1:51:27<00:00, 11.15s/it]\n"
     ]
    }
   ],
   "source": [
    "for question_id, question in tqdm(df.iterrows(), total=len(df)):\n",
    "  options_formatted = format_options(question.options)\n",
    "\n",
    "  for model in MODEL_LIST:\n",
    "    try:\n",
    "      first_prompt = SELECT_ANSWERS_PROMPT.format(answers_selected=answers_selected, question=question.question, options_formatted=options_formatted)\n",
    "      message_history, first_response = get_response(model, prompt = first_prompt, message_history=[])\n",
    "\n",
    "\n",
    "      _, second_response = get_response(model, prompt = SELECT_BEST_OPTION_PROMPT, message_history=message_history)\n",
    "      try:\n",
    "        option, reason, confidence = parse_select_best_option(second_response)\n",
    "      except Exception:\n",
    "        print('Error parsing response')\n",
    "        continue\n",
    "\n",
    "      # Save the information\n",
    "      dicts[model]['question'].append(question.question)\n",
    "      dicts[model]['question_id'].append(question_id)  \n",
    "      dicts[model]['category'].append(question.category)\n",
    "      dicts[model]['correct_answer'].append(question.answer_index)\n",
    "      dicts[model]['first_prompt'].append(first_prompt)\n",
    "      dicts[model]['first_response'].append(first_response)\n",
    "      dicts[model]['second_response'].append(second_response)\n",
    "      dicts[model]['options'].append(options_formatted)\n",
    "      dicts[model]['selected_option'].append(option)\n",
    "      dicts[model]['reason'].append(reason)\n",
    "      dicts[model]['confidence'].append(confidence)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "      print(f'Error with model: {model} error: {str(e)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "Uhsk3s-0nfGt"
   },
   "outputs": [],
   "source": [
    "monolothic_dfs = {model:pd.DataFrame(data=model_dict, index=model_dict['question_id']) for model, model_dict in dicts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "CbPZOWFxNV56",
    "outputId": "46aa353f-d8ad-4180-b985-7b250929272f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "      <th>category</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>first_prompt</th>\n",
       "      <th>first_response</th>\n",
       "      <th>second_response</th>\n",
       "      <th>selected_option</th>\n",
       "      <th>reason</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8603</th>\n",
       "      <td>8603</td>\n",
       "      <td>Compute the area of the triangle whose altitud...</td>\n",
       "      <td>0. 56\\sqrt{15}\\n1. 60\\sqrt{7}\\n2. 240\\sqrt{7}/...</td>\n",
       "      <td>math</td>\n",
       "      <td>2</td>\n",
       "      <td>\\nYou will be given a multiple-choice question...</td>\n",
       "      <td>Option: 2  \\nJustification: The area can be co...</td>\n",
       "      <td>Final Answer: 2  \\nReason: Option 2 aligns pre...</td>\n",
       "      <td>2</td>\n",
       "      <td>Option 2 aligns precisely with the known formu...</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>1663</td>\n",
       "      <td>What is the relationship between the formal so...</td>\n",
       "      <td>0. Treaties supersede custom\\n1. Treaties and ...</td>\n",
       "      <td>law</td>\n",
       "      <td>9</td>\n",
       "      <td>\\nYou will be given a multiple-choice question...</td>\n",
       "      <td>Option: 6\\nJustification: This recognizes the ...</td>\n",
       "      <td>Final Answer: 6  \\nReason: It acknowledges the...</td>\n",
       "      <td>6</td>\n",
       "      <td>It acknowledges the flexible and case-by-case ...</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>7113</td>\n",
       "      <td>The elasticity of supply is typically greater ...</td>\n",
       "      <td>0. producers have less capital to invest.\\n1. ...</td>\n",
       "      <td>economics</td>\n",
       "      <td>6</td>\n",
       "      <td>\\nYou will be given a multiple-choice question...</td>\n",
       "      <td>Option: 6\\nJustification: Producers have more ...</td>\n",
       "      <td>Final Answer: 6  \\nReason: Having more time to...</td>\n",
       "      <td>6</td>\n",
       "      <td>Having more time to respond allows producers t...</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>6220</td>\n",
       "      <td>Which of the following conditions is a peroxis...</td>\n",
       "      <td>0. Zellweger syndrome\\n1. Maple syrup urine di...</td>\n",
       "      <td>health</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nYou will be given a multiple-choice question...</td>\n",
       "      <td>Option: 0  \\nJustification: Zellweger syndrome...</td>\n",
       "      <td>Final Answer: 0  \\nReason: Zellweger syndrome ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Zellweger syndrome is a prototypical peroxisom...</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10472</th>\n",
       "      <td>10472</td>\n",
       "      <td>Define the following terms, making clear the d...</td>\n",
       "      <td>0. Byte is a collection of 4 bits, Bit is the ...</td>\n",
       "      <td>computer science</td>\n",
       "      <td>9</td>\n",
       "      <td>\\nYou will be given a multiple-choice question...</td>\n",
       "      <td>Option: 9\\nJustification: This option correctl...</td>\n",
       "      <td>Final Answer: 9  \\nReason: It accurately defin...</td>\n",
       "      <td>9</td>\n",
       "      <td>It accurately defines all three terms with sta...</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>2635</td>\n",
       "      <td>Piaget’s theory describes stages of cognitive ...</td>\n",
       "      <td>0. During adolescence only\\n1. From birth to l...</td>\n",
       "      <td>psychology</td>\n",
       "      <td>9</td>\n",
       "      <td>\\nYou will be given a multiple-choice question...</td>\n",
       "      <td>Option: 7\\nJustification: Piaget’s theory desc...</td>\n",
       "      <td>Final Answer: 7  \\nReason: Option 7 accurately...</td>\n",
       "      <td>7</td>\n",
       "      <td>Option 7 accurately captures the comprehensive...</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>3404</td>\n",
       "      <td>Assume a population of garden peas in genetic ...</td>\n",
       "      <td>0. 0.54FF + 0.12Ff + 0.34ff\\n1. 0.42FF + 0.36F...</td>\n",
       "      <td>biology</td>\n",
       "      <td>5</td>\n",
       "      <td>\\nYou will be given a multiple-choice question...</td>\n",
       "      <td>Option: 1  \\nJustification: Starting from init...</td>\n",
       "      <td>Final Answer: 1  \\nReason: Option 1 more accur...</td>\n",
       "      <td>1</td>\n",
       "      <td>Option 1 more accurately reflects the expected...</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>5034</td>\n",
       "      <td>Which culture, previously-known as the temple-...</td>\n",
       "      <td>0. Hohokam\\n1. Folsom\\n2. Adena\\n3. Ancestral ...</td>\n",
       "      <td>history</td>\n",
       "      <td>4</td>\n",
       "      <td>\\nYou will be given a multiple-choice question...</td>\n",
       "      <td>Option: 3  \\nJustification: The Ancestral Pueb...</td>\n",
       "      <td>Final Answer: 4  \\nReason: The Mississippian c...</td>\n",
       "      <td>4</td>\n",
       "      <td>The Mississippian culture is more widely recog...</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10380</th>\n",
       "      <td>10380</td>\n",
       "      <td>Which of the following is NOT a reasonable jus...</td>\n",
       "      <td>0. There is no other work for the processor to...</td>\n",
       "      <td>computer science</td>\n",
       "      <td>2</td>\n",
       "      <td>\\nYou will be given a multiple-choice question...</td>\n",
       "      <td>Option: 1\\nJustification: Busy-waiting is gene...</td>\n",
       "      <td>Final Answer: 3\\nReason: Waiting for immediate...</td>\n",
       "      <td>3</td>\n",
       "      <td>Waiting for immediate response upon event comp...</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11268</th>\n",
       "      <td>11268</td>\n",
       "      <td>The goal of cognitive-behavioral therapy is to</td>\n",
       "      <td>0. enhance physical strength.\\n1. reward good ...</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>8</td>\n",
       "      <td>\\nYou will be given a multiple-choice question...</td>\n",
       "      <td>Option: 1  \\nJustification: Cognitive-behavior...</td>\n",
       "      <td>Final Answer: 3  \\nReason: Increasing emotiona...</td>\n",
       "      <td>3</td>\n",
       "      <td>Increasing emotional intelligence is the prima...</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_id                                           question  \\\n",
       "8603          8603  Compute the area of the triangle whose altitud...   \n",
       "1663          1663  What is the relationship between the formal so...   \n",
       "7113          7113  The elasticity of supply is typically greater ...   \n",
       "6220          6220  Which of the following conditions is a peroxis...   \n",
       "10472        10472  Define the following terms, making clear the d...   \n",
       "...            ...                                                ...   \n",
       "2635          2635  Piaget’s theory describes stages of cognitive ...   \n",
       "3404          3404  Assume a population of garden peas in genetic ...   \n",
       "5034          5034  Which culture, previously-known as the temple-...   \n",
       "10380        10380  Which of the following is NOT a reasonable jus...   \n",
       "11268        11268     The goal of cognitive-behavioral therapy is to   \n",
       "\n",
       "                                                 options          category  \\\n",
       "8603   0. 56\\sqrt{15}\\n1. 60\\sqrt{7}\\n2. 240\\sqrt{7}/...              math   \n",
       "1663   0. Treaties supersede custom\\n1. Treaties and ...               law   \n",
       "7113   0. producers have less capital to invest.\\n1. ...         economics   \n",
       "6220   0. Zellweger syndrome\\n1. Maple syrup urine di...            health   \n",
       "10472  0. Byte is a collection of 4 bits, Bit is the ...  computer science   \n",
       "...                                                  ...               ...   \n",
       "2635   0. During adolescence only\\n1. From birth to l...        psychology   \n",
       "3404   0. 0.54FF + 0.12Ff + 0.34ff\\n1. 0.42FF + 0.36F...           biology   \n",
       "5034   0. Hohokam\\n1. Folsom\\n2. Adena\\n3. Ancestral ...           history   \n",
       "10380  0. There is no other work for the processor to...  computer science   \n",
       "11268  0. enhance physical strength.\\n1. reward good ...        philosophy   \n",
       "\n",
       "       correct_answer                                       first_prompt  \\\n",
       "8603                2  \\nYou will be given a multiple-choice question...   \n",
       "1663                9  \\nYou will be given a multiple-choice question...   \n",
       "7113                6  \\nYou will be given a multiple-choice question...   \n",
       "6220                0  \\nYou will be given a multiple-choice question...   \n",
       "10472               9  \\nYou will be given a multiple-choice question...   \n",
       "...               ...                                                ...   \n",
       "2635                9  \\nYou will be given a multiple-choice question...   \n",
       "3404                5  \\nYou will be given a multiple-choice question...   \n",
       "5034                4  \\nYou will be given a multiple-choice question...   \n",
       "10380               2  \\nYou will be given a multiple-choice question...   \n",
       "11268               8  \\nYou will be given a multiple-choice question...   \n",
       "\n",
       "                                          first_response  \\\n",
       "8603   Option: 2  \\nJustification: The area can be co...   \n",
       "1663   Option: 6\\nJustification: This recognizes the ...   \n",
       "7113   Option: 6\\nJustification: Producers have more ...   \n",
       "6220   Option: 0  \\nJustification: Zellweger syndrome...   \n",
       "10472  Option: 9\\nJustification: This option correctl...   \n",
       "...                                                  ...   \n",
       "2635   Option: 7\\nJustification: Piaget’s theory desc...   \n",
       "3404   Option: 1  \\nJustification: Starting from init...   \n",
       "5034   Option: 3  \\nJustification: The Ancestral Pueb...   \n",
       "10380  Option: 1\\nJustification: Busy-waiting is gene...   \n",
       "11268  Option: 1  \\nJustification: Cognitive-behavior...   \n",
       "\n",
       "                                         second_response selected_option  \\\n",
       "8603   Final Answer: 2  \\nReason: Option 2 aligns pre...               2   \n",
       "1663   Final Answer: 6  \\nReason: It acknowledges the...               6   \n",
       "7113   Final Answer: 6  \\nReason: Having more time to...               6   \n",
       "6220   Final Answer: 0  \\nReason: Zellweger syndrome ...               0   \n",
       "10472  Final Answer: 9  \\nReason: It accurately defin...               9   \n",
       "...                                                  ...             ...   \n",
       "2635   Final Answer: 7  \\nReason: Option 7 accurately...               7   \n",
       "3404   Final Answer: 1  \\nReason: Option 1 more accur...               1   \n",
       "5034   Final Answer: 4  \\nReason: The Mississippian c...               4   \n",
       "10380  Final Answer: 3\\nReason: Waiting for immediate...               3   \n",
       "11268  Final Answer: 3  \\nReason: Increasing emotiona...               3   \n",
       "\n",
       "                                                  reason confidence  \n",
       "8603   Option 2 aligns precisely with the known formu...        0.9  \n",
       "1663   It acknowledges the flexible and case-by-case ...        0.9  \n",
       "7113   Having more time to respond allows producers t...        0.9  \n",
       "6220   Zellweger syndrome is a prototypical peroxisom...       0.95  \n",
       "10472  It accurately defines all three terms with sta...       0.90  \n",
       "...                                                  ...        ...  \n",
       "2635   Option 7 accurately captures the comprehensive...        0.9  \n",
       "3404   Option 1 more accurately reflects the expected...       0.85  \n",
       "5034   The Mississippian culture is more widely recog...        0.9  \n",
       "10380  Waiting for immediate response upon event comp...       0.90  \n",
       "11268  Increasing emotional intelligence is the prima...        0.9  \n",
       "\n",
       "[600 rows x 11 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monolothic_dfs[MODEL_LIST[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "Qc27Kgv0Nh7d"
   },
   "outputs": [],
   "source": [
    "# Save the CSV files\n",
    "for model_name, model_df in monolothic_dfs.items():\n",
    "  model_df.to_csv('monolithic_' + model_name.replace('/', '_') + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fWjtTJ5H1-I"
   },
   "source": [
    "# Judge-based systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1JkA_UrUe9o"
   },
   "source": [
    "## Participant mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIhS-zPDVTtg",
    "outputId": "f2ce6d62-b20e-4f06-9b49-2b6f03004b24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'openai/openai/gpt-4.1-nano': {'question_id': [],\n",
       "  'question': [],\n",
       "  'options': [],\n",
       "  'category': [],\n",
       "  'correct_answer': [],\n",
       "  'model_responses': [],\n",
       "  'judge_prompt': [],\n",
       "  'judge_response': [],\n",
       "  'summary': [],\n",
       "  'selected_option': [],\n",
       "  'reason': [],\n",
       "  'confidence': [],\n",
       "  'judge_original_response': [],\n",
       "  'judge_original_option_selected': [],\n",
       "  'judge_original_confidence': []},\n",
       " 'anthropic/anthropic/claude-3-5-haiku-latest': {'question_id': [],\n",
       "  'question': [],\n",
       "  'options': [],\n",
       "  'category': [],\n",
       "  'correct_answer': [],\n",
       "  'model_responses': [],\n",
       "  'judge_prompt': [],\n",
       "  'judge_response': [],\n",
       "  'summary': [],\n",
       "  'selected_option': [],\n",
       "  'reason': [],\n",
       "  'confidence': [],\n",
       "  'judge_original_response': [],\n",
       "  'judge_original_option_selected': [],\n",
       "  'judge_original_confidence': []},\n",
       " 'gemini/gemini/gemini-2.0-flash': {'question_id': [],\n",
       "  'question': [],\n",
       "  'options': [],\n",
       "  'category': [],\n",
       "  'correct_answer': [],\n",
       "  'model_responses': [],\n",
       "  'judge_prompt': [],\n",
       "  'judge_response': [],\n",
       "  'summary': [],\n",
       "  'selected_option': [],\n",
       "  'reason': [],\n",
       "  'confidence': [],\n",
       "  'judge_original_response': [],\n",
       "  'judge_original_option_selected': [],\n",
       "  'judge_original_confidence': []}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionaries that are going to be used to created the DataFrames storing each model's responses\n",
    "dicts_jugdes_participants = {model: {'question_id': [], 'question': [], 'options': [], 'category': [], 'correct_answer': [], 'model_responses': [],\n",
    "                     'judge_prompt': [],'judge_response':[], 'summary':[] ,'selected_option': [], 'reason': [], 'confidence': [],\n",
    "                                     'judge_original_response':[], 'judge_original_option_selected': [], 'judge_original_confidence': []} for model in MODEL_LIST}\n",
    "dicts_jugdes_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7sT9qrkERIQw",
    "outputId": "d7ddd2de-7f0d-41c7-9692-9d5d8af30154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge: openai/openai/gpt-4.1-nano\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▊                                                            | 149/600 [01:23<04:36,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████▉                                       | 307/600 [01:49<00:52,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|███████████████████████████████████████████████████▋                            | 388/600 [02:24<01:21,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████                         | 413/600 [02:31<01:06,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████████████▋                    | 448/600 [02:56<01:19,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████████▍                   | 453/600 [03:18<04:29,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████▎            | 505/600 [07:17<08:55,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████████▍          | 521/600 [08:32<06:38,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████▎       | 542/600 [10:20<05:32,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████████████████████████████████████████▏      | 549/600 [10:58<05:03,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████▋     | 560/600 [11:58<03:58,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████████████████▏  | 579/600 [13:29<01:39,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████████████████████████████████████████████▋ | 590/600 [14:29<00:50,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████████████▎| 595/600 [14:54<00:27,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [15:24<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge: anthropic/anthropic/claude-3-5-haiku-latest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                 | 4/600 [00:22<56:22,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                               | 15/600 [01:17<50:45,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▌                                                                             | 26/600 [02:08<47:27,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▍                                                                           | 40/600 [03:18<46:13,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████                                                                          | 52/600 [04:17<48:30,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▌                                                                         | 56/600 [04:36<45:06,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▌                                                                        | 63/600 [05:12<44:11,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▋                                                                      | 79/600 [06:32<43:07,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▏                                                                     | 83/600 [06:53<43:19,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▏                                                                 | 106/600 [08:42<39:43,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▎                                                               | 122/600 [09:53<35:11,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▍                                                               | 123/600 [09:58<35:18,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████▋                                                               | 125/600 [10:07<35:57,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████▊                                                               | 126/600 [10:13<39:47,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▊                                                              | 134/600 [10:52<39:54,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▊                                                         | 171/600 [13:48<35:09,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████▏                                                        | 174/600 [14:03<34:09,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████                                                       | 188/600 [15:12<35:31,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████████████████▊                                                      | 194/600 [15:39<31:49,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████                                                  | 225/600 [18:03<29:14,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████▉                                                 | 232/600 [18:37<30:35,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████████████████████▊                                               | 246/600 [19:48<33:17,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████▌                                            | 267/600 [21:33<27:01,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████                                         | 293/600 [23:43<24:10,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████▎                                 | 347/600 [28:19<23:33,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████▎                            | 385/600 [31:33<18:38,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████▏                          | 399/600 [32:50<20:25,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████▊                         | 411/600 [33:56<16:17,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████                         | 413/600 [34:06<16:03,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████████▋                      | 433/600 [35:48<13:36,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████▏                    | 444/600 [36:43<13:16,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████▍                    | 446/600 [36:54<13:34,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████▌                    | 447/600 [37:00<14:31,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error original response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████████████▊                    | 449/600 [37:11<13:52,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████████▊                   | 456/600 [37:44<11:43,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████████▌                 | 469/600 [38:51<11:44,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████████                 | 473/600 [39:14<11:53,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████████▍                | 476/600 [39:29<11:06,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████▌                | 477/600 [39:36<11:56,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████▎             | 497/600 [41:17<08:41,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████████▎          | 520/600 [43:16<06:26,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|███████████████████████████████████████████████████████████████████████▍        | 536/600 [44:57<06:35,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████▍       | 543/600 [45:38<05:37,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████████████████████████████████████████████▋       | 545/600 [45:49<05:13,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████▍     | 558/600 [47:11<04:29,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████▌     | 559/600 [47:18<04:26,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████████████████████████████▊     | 561/600 [47:29<03:48,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████████████████████████████████████████    | 570/600 [48:22<02:51,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████████████████████████████████████████████████████████████████████████▎  | 580/600 [49:29<02:12,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████████████ | 593/600 [50:47<00:45,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████████████▏| 594/600 [50:53<00:39,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [51:31<00:00,  5.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge: gemini/gemini/gemini-2.0-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                            | 36/600 [00:59<48:29,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████▏                                              | 249/600 [06:17<07:08,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [14:50<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "for judge_model in MODEL_LIST:\n",
    "  print('Judge: ' + judge_model)\n",
    "\n",
    "  for question_idx in tqdm(df.index):\n",
    "    # If the question has already been proceded (this happens when restoring a backup)\n",
    "    if question_idx in dicts_jugdes_participants[judge_model]['question_id']:\n",
    "        continue\n",
    "        \n",
    "    question = df.loc[question_idx, 'question']\n",
    "    options_formatted = format_options(df.loc[question_idx, 'options'])\n",
    "    correct_answer = df.loc[question_idx, 'answer_index']\n",
    "    category = df.loc[question_idx, 'category']\n",
    "\n",
    "\n",
    "    model_responses = \"\"\n",
    "    for responder_model_idx, responder_model in enumerate(MODEL_LIST):\n",
    "      monolothic_df = monolothic_dfs[responder_model]\n",
    "      first_response = monolothic_df.loc[question_idx, 'first_response']\n",
    "      second_response = monolothic_df.loc[question_idx, 'second_response']\n",
    "\n",
    "      # If these are the original responses of the model being used as judge, we save them to calculate self-promotion later\n",
    "      if responder_model == judge_model:\n",
    "        judge_original_response = second_response\n",
    "        try:\n",
    "          judge_original_option_selected, _, judge_original_confidence = parse_select_best_option(second_response)\n",
    "        except Exception:\n",
    "          print('Error original response')\n",
    "          judge_original_option_selected, judge_original_confidence = '', '' # Not necessary to fail in this case\n",
    "\n",
    "\n",
    "\n",
    "      model_responses += f\"-------------Model {str(responder_model_idx)} responses-------------\\n{first_response}\\n\\n\\n{second_response}\\n\\n\"\n",
    "\n",
    "    judge_prompt = JUDGE_COMPARISON_PROMPT.format(answers_selected=answers_selected.capitalize(),\n",
    "                                                  question=question, options_formatted=options_formatted, model_responses=model_responses)\n",
    "\n",
    "\n",
    "    _, judge_response = get_response(judge_model, judge_prompt, message_history=[])\n",
    "\n",
    "\n",
    "    try:\n",
    "        summary, selected_option, reason, confidence = parse_judge_evaluation(judge_response)\n",
    "    except Exception:\n",
    "        print('Error parsing response')\n",
    "        continue\n",
    "\n",
    "\n",
    "    dicts_jugdes_participants[judge_model]['question_id'].append(question_idx)\n",
    "    dicts_jugdes_participants[judge_model]['question'].append(question)\n",
    "    dicts_jugdes_participants[judge_model]['options'].append(options_formatted)\n",
    "    dicts_jugdes_participants[judge_model]['correct_answer'].append(correct_answer)\n",
    "    dicts_jugdes_participants[judge_model]['category'].append(category)\n",
    "    dicts_jugdes_participants[judge_model]['judge_prompt'].append(judge_prompt)\n",
    "    dicts_jugdes_participants[judge_model]['model_responses'].append(model_responses)\n",
    "    dicts_jugdes_participants[judge_model]['judge_response'].append(judge_response)\n",
    "    dicts_jugdes_participants[judge_model]['reason'].append(reason)\n",
    "    dicts_jugdes_participants[judge_model]['summary'].append(summary)\n",
    "    dicts_jugdes_participants[judge_model]['selected_option'].append(selected_option)\n",
    "    dicts_jugdes_participants[judge_model]['confidence'].append(confidence)\n",
    "    dicts_jugdes_participants[judge_model]['judge_original_response'].append(judge_original_response)\n",
    "    dicts_jugdes_participants[judge_model]['judge_original_option_selected'].append(judge_original_option_selected)\n",
    "    dicts_jugdes_participants[judge_model]['judge_original_confidence'].append(judge_original_confidence)\n",
    "\n",
    "    # The output of tqdm is not complete since some judges where ran in parallel using different notebooks \n",
    "    # and the samples with parsing errors where retried afterwards  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts_jugdes_participants = {model:pd.DataFrame(data=model_dict) for model, model_dict in dicts_jugdes_participants.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "      <th>category</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>model_responses</th>\n",
       "      <th>judge_prompt</th>\n",
       "      <th>judge_response</th>\n",
       "      <th>summary</th>\n",
       "      <th>selected_option</th>\n",
       "      <th>reason</th>\n",
       "      <th>confidence</th>\n",
       "      <th>judge_original_response</th>\n",
       "      <th>judge_original_option_selected</th>\n",
       "      <th>judge_original_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compute the area of the triangle whose altitud...</td>\n",
       "      <td>Compute the area of the triangle whose altitud...</td>\n",
       "      <td>0. 56\\sqrt{15}\\n1. 60\\sqrt{7}\\n2. 240\\sqrt{7}/...</td>\n",
       "      <td>math</td>\n",
       "      <td>2</td>\n",
       "      <td>-------------Model 0 responses-------------\\nO...</td>\n",
       "      <td>\\nYou are an expert evaluator reviewing respon...</td>\n",
       "      <td>Evaluation Summary:\\nModel 0: Justifications a...</td>\n",
       "      <td>Model 0: Justifications are vague and lack spe...</td>\n",
       "      <td>2</td>\n",
       "      <td>Model 2 provides a complete and correct deriva...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Final Answer: 2\\nReason: The calculation in op...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the relationship between the formal so...</td>\n",
       "      <td>What is the relationship between the formal so...</td>\n",
       "      <td>0. Treaties supersede custom\\n1. Treaties and ...</td>\n",
       "      <td>law</td>\n",
       "      <td>9</td>\n",
       "      <td>-------------Model 0 responses-------------\\nO...</td>\n",
       "      <td>\\nYou are an expert evaluator reviewing respon...</td>\n",
       "      <td>Evaluation Summary:\\nModel 0: Strong justifica...</td>\n",
       "      <td>Model 0: Strong justifications, correct final ...</td>\n",
       "      <td>9</td>\n",
       "      <td>Article 38 of the ICJ Statute does not establi...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Final Answer: 9\\nReason: Option 9 is stronger ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The elasticity of supply is typically greater ...</td>\n",
       "      <td>The elasticity of supply is typically greater ...</td>\n",
       "      <td>0. producers have less capital to invest.\\n1. ...</td>\n",
       "      <td>economics</td>\n",
       "      <td>6</td>\n",
       "      <td>-------------Model 0 responses-------------\\nO...</td>\n",
       "      <td>\\nYou are an expert evaluator reviewing respon...</td>\n",
       "      <td>Evaluation Summary:\\nModel 0: Correct answer a...</td>\n",
       "      <td>Model 0: Correct answer and strong justificati...</td>\n",
       "      <td>6</td>\n",
       "      <td>Elasticity of supply refers to the responsiven...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Final Answer: 6\\nReason: Option 6, regarding t...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which of the following conditions is a peroxis...</td>\n",
       "      <td>Which of the following conditions is a peroxis...</td>\n",
       "      <td>0. Zellweger syndrome\\n1. Maple syrup urine di...</td>\n",
       "      <td>health</td>\n",
       "      <td>0</td>\n",
       "      <td>-------------Model 0 responses-------------\\nO...</td>\n",
       "      <td>\\nYou are an expert evaluator reviewing respon...</td>\n",
       "      <td>Evaluation Summary:\\nModel 0: Correct and well...</td>\n",
       "      <td>Model 0: Correct and well-justified.\\nModel 1:...</td>\n",
       "      <td>0</td>\n",
       "      <td>Zellweger syndrome is a peroxisomal biogenesis...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Final Answer: 0\\nReason: Zellweger syndrome is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Define the following terms, making clear the d...</td>\n",
       "      <td>Define the following terms, making clear the d...</td>\n",
       "      <td>0. Byte is a collection of 4 bits, Bit is the ...</td>\n",
       "      <td>computer science</td>\n",
       "      <td>9</td>\n",
       "      <td>-------------Model 0 responses-------------\\nO...</td>\n",
       "      <td>\\nYou are an expert evaluator reviewing respon...</td>\n",
       "      <td>Evaluation Summary:\\nModel 0: Accurate and wel...</td>\n",
       "      <td>Model 0: Accurate and well-reasoned.\\nModel 1:...</td>\n",
       "      <td>9</td>\n",
       "      <td>Option 9 correctly defines bit, byte, and word...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Final Answer: 9\\nReason: Option 9 accurately d...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Piaget’s theory describes stages of cognitive ...</td>\n",
       "      <td>Piaget’s theory describes stages of cognitive ...</td>\n",
       "      <td>0. During adolescence only\\n1. From birth to l...</td>\n",
       "      <td>psychology</td>\n",
       "      <td>9</td>\n",
       "      <td>-------------Model 0 responses-------------\\nO...</td>\n",
       "      <td>\\nYou are an expert evaluator reviewing respon...</td>\n",
       "      <td>Evaluation Summary:\\nModel 0: The justificatio...</td>\n",
       "      <td>Model 0: The justification for option 7 is inc...</td>\n",
       "      <td>4</td>\n",
       "      <td>Piaget's theory outlines stages of cognitive d...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Final Answer: 4\\nReason: Option 4 more accurat...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>Assume a population of garden peas in genetic ...</td>\n",
       "      <td>Assume a population of garden peas in genetic ...</td>\n",
       "      <td>0. 0.54FF + 0.12Ff + 0.34ff\\n1. 0.42FF + 0.36F...</td>\n",
       "      <td>biology</td>\n",
       "      <td>5</td>\n",
       "      <td>-------------Model 0 responses-------------\\nO...</td>\n",
       "      <td>\\nYou are an expert evaluator reviewing respon...</td>\n",
       "      <td>Evaluation Summary:\\nModel 0: Incorrect final ...</td>\n",
       "      <td>Model 0: Incorrect final answer. The justifica...</td>\n",
       "      <td>5</td>\n",
       "      <td>The initial genotype frequencies are FF = 0.36...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Final Answer: 5\\nReason: Option 5 provides the...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Which culture, previously-known as the temple-...</td>\n",
       "      <td>Which culture, previously-known as the temple-...</td>\n",
       "      <td>0. Hohokam\\n1. Folsom\\n2. Adena\\n3. Ancestral ...</td>\n",
       "      <td>history</td>\n",
       "      <td>4</td>\n",
       "      <td>-------------Model 0 responses-------------\\nO...</td>\n",
       "      <td>\\nYou are an expert evaluator reviewing respon...</td>\n",
       "      <td>Evaluation Summary:\\nModel 0: The justificatio...</td>\n",
       "      <td>Model 0: The justifications are accurate and r...</td>\n",
       "      <td>4</td>\n",
       "      <td>The Mississippian culture is widely recognized...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Final Answer: 4\\nReason: While Moundville is r...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Which of the following is NOT a reasonable jus...</td>\n",
       "      <td>Which of the following is NOT a reasonable jus...</td>\n",
       "      <td>0. There is no other work for the processor to...</td>\n",
       "      <td>computer science</td>\n",
       "      <td>2</td>\n",
       "      <td>-------------Model 0 responses-------------\\nO...</td>\n",
       "      <td>\\nYou are an expert evaluator reviewing respon...</td>\n",
       "      <td>Evaluation Summary:\\nModel 0: The justificatio...</td>\n",
       "      <td>Model 0: The justifications for both options a...</td>\n",
       "      <td>2</td>\n",
       "      <td>Busy-waiting wastes CPU cycles, which is detri...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Final Answer: 2\\nReason: Option 2 highlights a...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>The goal of cognitive-behavioral therapy is to</td>\n",
       "      <td>The goal of cognitive-behavioral therapy is to</td>\n",
       "      <td>0. enhance physical strength.\\n1. reward good ...</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>8</td>\n",
       "      <td>-------------Model 0 responses-------------\\nO...</td>\n",
       "      <td>\\nYou are an expert evaluator reviewing respon...</td>\n",
       "      <td>Evaluation Summary:\\nModel 0: The justificatio...</td>\n",
       "      <td>Model 0: The justifications are reasonable, an...</td>\n",
       "      <td>3</td>\n",
       "      <td>Cognitive-behavioral therapy (CBT) aims to imp...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>Final Answer: 3\\nReason: Emotional intelligenc...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question_id  \\\n",
       "0    Compute the area of the triangle whose altitud...   \n",
       "1    What is the relationship between the formal so...   \n",
       "2    The elasticity of supply is typically greater ...   \n",
       "3    Which of the following conditions is a peroxis...   \n",
       "4    Define the following terms, making clear the d...   \n",
       "..                                                 ...   \n",
       "593  Piaget’s theory describes stages of cognitive ...   \n",
       "594  Assume a population of garden peas in genetic ...   \n",
       "595  Which culture, previously-known as the temple-...   \n",
       "596  Which of the following is NOT a reasonable jus...   \n",
       "597     The goal of cognitive-behavioral therapy is to   \n",
       "\n",
       "                                              question  \\\n",
       "0    Compute the area of the triangle whose altitud...   \n",
       "1    What is the relationship between the formal so...   \n",
       "2    The elasticity of supply is typically greater ...   \n",
       "3    Which of the following conditions is a peroxis...   \n",
       "4    Define the following terms, making clear the d...   \n",
       "..                                                 ...   \n",
       "593  Piaget’s theory describes stages of cognitive ...   \n",
       "594  Assume a population of garden peas in genetic ...   \n",
       "595  Which culture, previously-known as the temple-...   \n",
       "596  Which of the following is NOT a reasonable jus...   \n",
       "597     The goal of cognitive-behavioral therapy is to   \n",
       "\n",
       "                                               options          category  \\\n",
       "0    0. 56\\sqrt{15}\\n1. 60\\sqrt{7}\\n2. 240\\sqrt{7}/...              math   \n",
       "1    0. Treaties supersede custom\\n1. Treaties and ...               law   \n",
       "2    0. producers have less capital to invest.\\n1. ...         economics   \n",
       "3    0. Zellweger syndrome\\n1. Maple syrup urine di...            health   \n",
       "4    0. Byte is a collection of 4 bits, Bit is the ...  computer science   \n",
       "..                                                 ...               ...   \n",
       "593  0. During adolescence only\\n1. From birth to l...        psychology   \n",
       "594  0. 0.54FF + 0.12Ff + 0.34ff\\n1. 0.42FF + 0.36F...           biology   \n",
       "595  0. Hohokam\\n1. Folsom\\n2. Adena\\n3. Ancestral ...           history   \n",
       "596  0. There is no other work for the processor to...  computer science   \n",
       "597  0. enhance physical strength.\\n1. reward good ...        philosophy   \n",
       "\n",
       "     correct_answer                                    model_responses  \\\n",
       "0                 2  -------------Model 0 responses-------------\\nO...   \n",
       "1                 9  -------------Model 0 responses-------------\\nO...   \n",
       "2                 6  -------------Model 0 responses-------------\\nO...   \n",
       "3                 0  -------------Model 0 responses-------------\\nO...   \n",
       "4                 9  -------------Model 0 responses-------------\\nO...   \n",
       "..              ...                                                ...   \n",
       "593               9  -------------Model 0 responses-------------\\nO...   \n",
       "594               5  -------------Model 0 responses-------------\\nO...   \n",
       "595               4  -------------Model 0 responses-------------\\nO...   \n",
       "596               2  -------------Model 0 responses-------------\\nO...   \n",
       "597               8  -------------Model 0 responses-------------\\nO...   \n",
       "\n",
       "                                          judge_prompt  \\\n",
       "0    \\nYou are an expert evaluator reviewing respon...   \n",
       "1    \\nYou are an expert evaluator reviewing respon...   \n",
       "2    \\nYou are an expert evaluator reviewing respon...   \n",
       "3    \\nYou are an expert evaluator reviewing respon...   \n",
       "4    \\nYou are an expert evaluator reviewing respon...   \n",
       "..                                                 ...   \n",
       "593  \\nYou are an expert evaluator reviewing respon...   \n",
       "594  \\nYou are an expert evaluator reviewing respon...   \n",
       "595  \\nYou are an expert evaluator reviewing respon...   \n",
       "596  \\nYou are an expert evaluator reviewing respon...   \n",
       "597  \\nYou are an expert evaluator reviewing respon...   \n",
       "\n",
       "                                        judge_response  \\\n",
       "0    Evaluation Summary:\\nModel 0: Justifications a...   \n",
       "1    Evaluation Summary:\\nModel 0: Strong justifica...   \n",
       "2    Evaluation Summary:\\nModel 0: Correct answer a...   \n",
       "3    Evaluation Summary:\\nModel 0: Correct and well...   \n",
       "4    Evaluation Summary:\\nModel 0: Accurate and wel...   \n",
       "..                                                 ...   \n",
       "593  Evaluation Summary:\\nModel 0: The justificatio...   \n",
       "594  Evaluation Summary:\\nModel 0: Incorrect final ...   \n",
       "595  Evaluation Summary:\\nModel 0: The justificatio...   \n",
       "596  Evaluation Summary:\\nModel 0: The justificatio...   \n",
       "597  Evaluation Summary:\\nModel 0: The justificatio...   \n",
       "\n",
       "                                               summary selected_option  \\\n",
       "0    Model 0: Justifications are vague and lack spe...               2   \n",
       "1    Model 0: Strong justifications, correct final ...               9   \n",
       "2    Model 0: Correct answer and strong justificati...               6   \n",
       "3    Model 0: Correct and well-justified.\\nModel 1:...               0   \n",
       "4    Model 0: Accurate and well-reasoned.\\nModel 1:...               9   \n",
       "..                                                 ...             ...   \n",
       "593  Model 0: The justification for option 7 is inc...               4   \n",
       "594  Model 0: Incorrect final answer. The justifica...               5   \n",
       "595  Model 0: The justifications are accurate and r...               4   \n",
       "596  Model 0: The justifications for both options a...               2   \n",
       "597  Model 0: The justifications are reasonable, an...               3   \n",
       "\n",
       "                                                reason confidence  \\\n",
       "0    Model 2 provides a complete and correct deriva...        1.0   \n",
       "1    Article 38 of the ICJ Statute does not establi...       0.95   \n",
       "2    Elasticity of supply refers to the responsiven...        1.0   \n",
       "3    Zellweger syndrome is a peroxisomal biogenesis...        1.0   \n",
       "4    Option 9 correctly defines bit, byte, and word...        1.0   \n",
       "..                                                 ...        ...   \n",
       "593  Piaget's theory outlines stages of cognitive d...       0.95   \n",
       "594  The initial genotype frequencies are FF = 0.36...        1.0   \n",
       "595  The Mississippian culture is widely recognized...        1.0   \n",
       "596  Busy-waiting wastes CPU cycles, which is detri...       0.95   \n",
       "597  Cognitive-behavioral therapy (CBT) aims to imp...       0.99   \n",
       "\n",
       "                               judge_original_response  \\\n",
       "0    Final Answer: 2\\nReason: The calculation in op...   \n",
       "1    Final Answer: 9\\nReason: Option 9 is stronger ...   \n",
       "2    Final Answer: 6\\nReason: Option 6, regarding t...   \n",
       "3    Final Answer: 0\\nReason: Zellweger syndrome is...   \n",
       "4    Final Answer: 9\\nReason: Option 9 accurately d...   \n",
       "..                                                 ...   \n",
       "593  Final Answer: 4\\nReason: Option 4 more accurat...   \n",
       "594  Final Answer: 5\\nReason: Option 5 provides the...   \n",
       "595  Final Answer: 4\\nReason: While Moundville is r...   \n",
       "596  Final Answer: 2\\nReason: Option 2 highlights a...   \n",
       "597  Final Answer: 3\\nReason: Emotional intelligenc...   \n",
       "\n",
       "    judge_original_option_selected judge_original_confidence  \n",
       "0                                2                      0.95  \n",
       "1                                9                       0.6  \n",
       "2                                6                      0.75  \n",
       "3                                0                      0.95  \n",
       "4                                9                      0.75  \n",
       "..                             ...                       ...  \n",
       "593                              4                      0.75  \n",
       "594                              5                      0.95  \n",
       "595                              4                       0.9  \n",
       "596                              2                      0.75  \n",
       "597                              3                      0.75  \n",
       "\n",
       "[598 rows x 15 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts_jugdes_participants[MODEL_LIST[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the CSV files\n",
    "for model_name, model_df in dicts_jugdes_participants.items():\n",
    "  model_df.to_csv('judge_participant_mode_' + model_name.replace('/', '_') + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator-only mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tGqmzE26Mry",
    "outputId": "877bd7cf-df0d-4d74-d2fd-026270449f24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'openai/openai/gpt-4.1-nano': {'question_id': [],\n",
       "  'question': [],\n",
       "  'options': [],\n",
       "  'category': [],\n",
       "  'correct_answer': [],\n",
       "  'model_responses': [],\n",
       "  'judge_prompt': [],\n",
       "  'judge_response': [],\n",
       "  'summary': [],\n",
       "  'selected_option': [],\n",
       "  'reason': [],\n",
       "  'confidence': []},\n",
       " 'anthropic/anthropic/claude-3-5-haiku-latest': {'question_id': [],\n",
       "  'question': [],\n",
       "  'options': [],\n",
       "  'category': [],\n",
       "  'correct_answer': [],\n",
       "  'model_responses': [],\n",
       "  'judge_prompt': [],\n",
       "  'judge_response': [],\n",
       "  'summary': [],\n",
       "  'selected_option': [],\n",
       "  'reason': [],\n",
       "  'confidence': []},\n",
       " 'gemini/gemini/gemini-2.0-flash': {'question_id': [],\n",
       "  'question': [],\n",
       "  'options': [],\n",
       "  'category': [],\n",
       "  'correct_answer': [],\n",
       "  'model_responses': [],\n",
       "  'judge_prompt': [],\n",
       "  'judge_response': [],\n",
       "  'summary': [],\n",
       "  'selected_option': [],\n",
       "  'reason': [],\n",
       "  'confidence': []}}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionaries that are going to be used to created the DataFrames storing each model's responses\n",
    "dicts_jugdes_evaluator = {model: {'question_id': [], 'question': [], 'options': [], 'category': [], 'correct_answer': [], 'model_responses': [],\n",
    "                     'judge_prompt': [],'judge_response':[], 'summary':[] ,'selected_option': [], 'reason': [], 'confidence': []} for model in MODEL_LIST}\n",
    "dicts_jugdes_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vnUmjrxU6Mrz",
    "outputId": "18387fd0-ce0b-4e67-a21d-a5b67a8061be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge: anthropic/anthropic/claude-3-5-haiku-latest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                               | 1/600 [00:06<1:00:45,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                               | 11/600 [01:00<57:35,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                               | 15/600 [01:19<50:11,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▊                                                                              | 21/600 [01:51<51:36,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████                                                                             | 30/600 [02:34<46:21,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                            | 36/600 [03:08<55:13,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▍                                                                           | 40/600 [03:29<52:41,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████                                                                          | 52/600 [04:34<53:36,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▌                                                                        | 63/600 [05:33<51:07,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▏                                                                     | 83/600 [07:24<47:01,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▋                                                                  | 103/600 [09:20<47:53,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▏                                                                 | 106/600 [09:38<47:21,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████▍                                                                | 116/600 [10:32<42:43,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▎                                                               | 122/600 [11:01<37:53,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▍                                                               | 123/600 [11:05<37:10,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▊                                                              | 134/600 [12:01<39:48,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████▋                                                           | 155/600 [13:58<40:56,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████▍                                                        | 176/600 [15:51<37:35,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████                                                       | 188/600 [16:47<32:55,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████████████████▍                                                      | 191/600 [17:02<32:24,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████████▎                                                   | 212/600 [18:40<30:31,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████                                                  | 225/600 [19:43<30:41,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████▏                                                 | 226/600 [19:48<30:20,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████▉                                                 | 232/600 [20:15<30:30,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████▊                                                | 239/600 [20:52<32:03,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████▏                                              | 249/600 [21:43<27:29,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████▍                                            | 266/600 [23:10<24:54,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████████▉                                           | 277/600 [24:06<26:34,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████                                         | 293/600 [25:23<28:19,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████▌                                        | 297/600 [25:42<25:30,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████████████▌                                     | 319/600 [27:41<23:25,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████▍                                   | 333/600 [28:50<23:49,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████▌                                   | 334/600 [28:55<23:03,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████████▏                                  | 339/600 [29:18<20:48,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████▏                                | 354/600 [30:30<19:01,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████▋                                | 358/600 [30:54<22:58,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████▎                               | 362/600 [31:16<22:21,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████▎                              | 370/600 [31:51<16:53,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▍                             | 378/600 [32:30<17:43,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████▉                           | 397/600 [34:06<17:33,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████▏                          | 399/600 [34:14<15:29,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████▊                        | 419/600 [35:49<14:53,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████████▋                      | 433/600 [36:57<14:41,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████▎                    | 445/600 [37:53<12:40,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████▍                    | 446/600 [37:58<12:53,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████████▊                   | 456/600 [38:46<10:52,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████████▏                | 474/600 [40:10<09:24,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████▌                | 477/600 [40:24<09:37,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████████████▌               | 484/600 [40:57<08:55,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████▌              | 492/600 [41:33<07:58,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████▋              | 493/600 [41:38<08:20,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████▎             | 497/600 [41:58<08:41,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████▌             | 499/600 [42:08<08:29,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████████▎          | 520/600 [43:57<06:57,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|███████████████████████████████████████████████████████████████████████▍        | 536/600 [45:15<04:49,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████▍       | 543/600 [45:50<04:27,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████▍     | 558/600 [47:02<03:26,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████▋     | 560/600 [47:11<03:09,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████████████████████████████████████████████████▋   | 575/600 [48:23<02:17,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████████████████████████████████████████████████████████████████████████▎  | 580/600 [48:50<01:46,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████████████████████████████████████████████████████████████████████████▍  | 581/600 [48:54<01:37,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████████████████████████████████████████████▋ | 590/600 [49:40<01:00,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|██████████████████████████████████████████████████████████████████████████████▉ | 592/600 [49:50<00:43,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████████████ | 593/600 [49:56<00:38,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████████████▎| 595/600 [50:05<00:25,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [50:30<00:00,  5.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge: gemini/gemini/gemini-2.0-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                            | 36/600 [00:52<36:26,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▏                                                                 | 106/600 [02:50<41:55,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████▏                                              | 249/600 [06:29<07:29,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████▎     | 557/600 [14:19<01:22,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [15:17<00:00,  1.53s/it]\n"
     ]
    }
   ],
   "source": [
    "for judge_model in MODEL_LIST:\n",
    "  print('Judge: ' + judge_model)\n",
    "\n",
    "  for question_idx in tqdm(df.index):\n",
    "    question = df.loc[question_idx, 'question']\n",
    "    options_formatted = format_options(df.loc[question_idx, 'options'])\n",
    "    correct_answer = df.loc[question_idx, 'answer_index']\n",
    "    category = df.loc[question_idx, 'category']\n",
    "\n",
    "    # If the question has already been proceded (this happens when restoring a backup)\n",
    "    if question_idx in dicts_jugdes_evaluator[judge_model]['question_id']:\n",
    "          continue\n",
    "\n",
    "    model_responses = \"\"\n",
    "    for responder_model_idx, responder_model in enumerate(MODEL_LIST):\n",
    "\n",
    "      # Don't show the model its original responses\n",
    "      if responder_model == judge_model:\n",
    "        continue\n",
    "\n",
    "      monolothic_df = monolothic_dfs[responder_model]\n",
    "      first_response = monolothic_df.loc[question_idx, 'first_response']\n",
    "      second_response = monolothic_df.loc[question_idx, 'second_response']\n",
    "      model_responses += f\"-------------Model {str(responder_model_idx)} responses-------------\\n{first_response}\\n\\n\\n{second_response}\\n\\n\"\n",
    "\n",
    "    judge_prompt = JUDGE_COMPARISON_PROMPT.format(answers_selected=answers_selected.capitalize(),\n",
    "                                                  question=question, options_formatted=options_formatted, model_responses=model_responses)\n",
    "\n",
    "\n",
    "    _, judge_response = get_response(judge_model, judge_prompt, message_history=[])\n",
    "\n",
    "\n",
    "    try:\n",
    "        summary, selected_option, reason, confidence = parse_judge_evaluation(judge_response)\n",
    "    except Exception:\n",
    "        print('Error parsing response')\n",
    "        continue\n",
    "\n",
    "    dicts_jugdes_evaluator[judge_model]['question_id'].append(question_idx)\n",
    "    dicts_jugdes_evaluator[judge_model]['question'].append(question)\n",
    "    dicts_jugdes_evaluator[judge_model]['options'].append(options_formatted)\n",
    "    dicts_jugdes_evaluator[judge_model]['correct_answer'].append(correct_answer)\n",
    "    dicts_jugdes_evaluator[judge_model]['category'].append(category)\n",
    "    dicts_jugdes_evaluator[judge_model]['judge_prompt'].append(judge_prompt)\n",
    "    dicts_jugdes_evaluator[judge_model]['model_responses'].append(model_responses)\n",
    "    dicts_jugdes_evaluator[judge_model]['judge_response'].append(judge_response)\n",
    "    dicts_jugdes_evaluator[judge_model]['reason'].append(reason)\n",
    "    dicts_jugdes_evaluator[judge_model]['summary'].append(summary)\n",
    "    dicts_jugdes_evaluator[judge_model]['selected_option'].append(selected_option)\n",
    "    dicts_jugdes_evaluator[judge_model]['confidence'].append(confidence)\n",
    "\n",
    "    # The output of tqdm is not complete since some judges where ran in parallel using different notebooks \n",
    "    # and the samples with parsing errors where retried afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "cBigx6IX6Mr0"
   },
   "outputs": [],
   "source": [
    "dicts_jugdes_evaluator = {model:pd.DataFrame(data=model_dict) for model, model_dict in dicts_jugdes_evaluator.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "7OuHtzFi6Mr1",
    "outputId": "dfec0bea-91d1-4296-f669-a46f1ce84e4a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "      <th>category</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>model_responses</th>\n",
       "      <th>judge_prompt</th>\n",
       "      <th>judge_response</th>\n",
       "      <th>summary</th>\n",
       "      <th>selected_option</th>\n",
       "      <th>reason</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [question_id, question, options, category, correct_answer, model_responses, judge_prompt, judge_response, summary, selected_option, reason, confidence]\n",
       "Index: []"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts_jugdes_evaluator[MODEL_LIST[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "3N4BNF4o6Mr3"
   },
   "outputs": [],
   "source": [
    "# Save the CSV files\n",
    "for model_name, model_df in dicts_jugdes_evaluator.items():\n",
    "  model_df.to_csv('judge_evaluator_only_mode_' + model_name.replace('/', '_') + '.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "V1JkA_UrUe9o"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
